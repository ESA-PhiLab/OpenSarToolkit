{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font face=\"Calibri\" size=\"2\"> <i>Open SAR Toolkit - Tutorial 4c, version 1.2, August 2020. Andreas Vollrath, ESA/ESRIN phi-lab</i>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](https://raw.githubusercontent.com/ESA-PhiLab/OpenSarToolkit/main/docs/source/_images/header_image.PNG)\n",
    "\n",
    "--------\n",
    "\n",
    "# OST Tutorial IV - C\n",
    "## Create country-wide mosaic time-series and timescan. Introduction to GRD Batch processing part III.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ESA-PhiLab/OST_Notebooks/blob/master/4c%20-%20Sentinel-1%20GRD%20Batch%20-%20Timescan.ipynb)\n",
    "\n",
    "--------\n",
    "\n",
    "**Short description**\n",
    "\n",
    "This notebook is very similar to the Tutorial IVa, with the difference that you will process GRD data over a larger area and create time-series and timescan mosaics. It therefore represents the workflow for large-scale processing.\n",
    "\n",
    "--------\n",
    "\n",
    "**Requirements**\n",
    "\n",
    "- a PC/Mac with at least 16GB of RAM\n",
    "- about 150GB of free disk space\n",
    "- a Copernicus Open Data Hub user account, valid for at least 7 days (https://scihub.copernicus.eu)\n",
    "--------\n",
    "\n",
    "**NOTE:** all cells that have an * after its number can be executed without changing any code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0\\* - Install OST and dependencies \n",
    "\n",
    "**NOTE:** Applies only if you haven't fully installed OST and its dependencies yet, e.g. on Google Colab, so uncomment the lines in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !apt-get -y install wget\n",
    "# !wget https://raw.githubusercontent.com/ESA-PhiLab/OST_Notebooks/master/install_ost.sh\n",
    "# !bash install_ost.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1* - Import of Libraries\n",
    "\n",
    "In this step we import some standard python libraries for OS independent path handling as well as the *Sentinel1_GRDBatch* class thta handles the full workflow from search, download and processing of multiple GRD scenes. In addition, the OST helper module *vector* is loaded to create an AOI based on Point coordinates, and the *raster* module for creating a time-series animation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "\n",
    "from ost import Sentinel1Batch\n",
    "from ost.helpers import vector, raster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2* - Set up the project \n",
    "\n",
    "Here you going to initialize the *Sentinel1_GRDBatch* class by determining the project folder, the AOI and the start and end date. Since you should be already familiar with the *search* and *refine* functions, we execute them within the same cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a project directory\n",
    "home = Path.home()\n",
    "# create a processing directory\n",
    "project_dir = home / \"OST_Tutorials\" / \"Tutorial_4c\"\n",
    "\n",
    "# define aoi with helper function, i.e. get a buffered area around point coordinates\n",
    "aoi = \"IRL\"\n",
    "\n",
    "# define the start and end date\n",
    "start = \"2019-02-01\"\n",
    "end = \"2019-04-30\"\n",
    "\n",
    "# initialize the class to s1_grd instance\n",
    "s1_grd = Sentinel1Batch(project_dir=project_dir, aoi=aoi, start=start, end=end, product_type=\"GRD\")\n",
    "\n",
    "# trigger the search\n",
    "s1_grd.search()\n",
    "\n",
    "# optional: once you did the search the first time, you can load\n",
    "# the full inventory uncommenting the follwoing 2 lines\n",
    "# and commenting the search command\n",
    "# s1_grd.inventory_file = s1_grd.inventory_dir/\"full.inventory.gpkg\"\n",
    "# s1_grd.read_inventory()\n",
    "\n",
    "# do the refinement\n",
    "s1_grd.refine_inventory()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3* - Plot refined data inventory\n",
    "\n",
    "Here you will visualize the resultant dataframes from the refined search inventory based on the product key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------\n",
    "# for plotting purposes we use this iPython magic\n",
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams[\"figure.figsize\"] = (19, 19)\n",
    "# ---------------------------------------------------\n",
    "\n",
    "# search command\n",
    "key = \"ASCENDING_VVVH\"\n",
    "nb_frames = len(s1_grd.refined_inventory_dict[key])\n",
    "print(f\"Our refined inventory holds {nb_frames} frames to process.\")\n",
    "\n",
    "# we plot the full Inventory on a map\n",
    "s1_grd.plot_inventory(s1_grd.refined_inventory_dict[key], transparency=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4* - Download of GRD scenes\n",
    "\n",
    "As already shown in Tutorial II, you will download the scenes based on the refined inventory dataframe for the respective produckt key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_grd.download(s1_grd.refined_inventory_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5* - Set ARD parameters\n",
    "\n",
    "Similar to the *Sentinel1-Scene* class (Tutorial I and III), the *Sentinel1-GRDBatch* class handles the defintion of ARD types in a hierarchical dictionary structure. You can use the same types and steps to customize as for the *Sentinel1-Scene* class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# single scene ARD parameters\n",
    "s1_grd.ard_parameters[\"single_ARD\"][\"resolution\"] = 50\n",
    "s1_grd.ard_parameters[\"single_ARD\"][\"product_type\"] = \"GTC-gamma0\"\n",
    "s1_grd.ard_parameters[\"single_ARD\"][\"create_ls_mask\"] = False\n",
    "\n",
    "# time-series ARD\n",
    "s1_grd.ard_parameters[\"time-series_ARD\"][\"remove_mt_speckle\"] = False\n",
    "\n",
    "# our borders for Ireland are quite rough. We therefore won't clip the final mosaics\n",
    "s1_grd.ard_parameters[\"mosaic\"][\"cut_to_aoi\"] = False\n",
    "\n",
    "# s1_grd.config_dict['temp_dir'] = '/ram'\n",
    "pprint(s1_grd.ard_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6* - Run the batch routine\n",
    "\n",
    "To process all the data, including time-series and timescans is as easy as one command. All the complexity is handled behind, and you just have to wait, since processing can take quite a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_grd.grds_to_ards(\n",
    "    inventory_df=s1_grd.refined_inventory_dict[key],\n",
    "    timeseries=True,\n",
    "    timescan=True,\n",
    "    overwrite=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7* - Create a time-series animation\n",
    "\n",
    "For interactive presentations it is nice to have animated \"movies\". The following command allows you to create animated time-series of oyur processed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Time-series folder\n",
    "ts_folder = s1_grd.processing_dir / \"23\" / \"Timeseries\"\n",
    "\n",
    "# create the animation\n",
    "raster.create_timeseries_animation(\n",
    "    timeseries_folder=ts_folder,\n",
    "    product_list=[\"bs.VV\", \"bs.VH\"],\n",
    "    out_folder=s1_grd.processing_dir,\n",
    "    shrink_factor=10,\n",
    "    add_dates=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
